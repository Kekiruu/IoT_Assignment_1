Designing and programming our MQTT-driven robot car was a long process with many steps and challenges, but I was very proud of the result.

The first step was to figure out what the project was going to look like hardware-wise. From the get-go, I wanted the hardware side of the project to be as quick and easy as possible, while still yielding a cool, tangible final result. I like projects that I can see and touch, but this project seemed to be really about software, so I wanted us to be able to focus all of our efforts there.

We decided that for the physical device, we would re-use the old Elegoo robot car from the first semester, since it had everything that we need for a microcontroller to control motors & sensors, in a familiar and reliable package. I happen to have laying around an ESP8266 board that is shaped exactly like an Arduino Uno, so my original idea was to just plug that ESP board into the robot's shield meant for an Arduino Uno, to securly connect the ESP's IO pins to the robot components. Unfortunately though, the pinout of this ESP board is not the same as the pinout that the shield is designed for, so plugging it into the shield would cause power pins to get shorted. The next option was to take advantage of the connection point on top of the shield for the Uno's UART pins. This allows us to leave the Arduino Uno in the robot, and have an ESP board command the arduino via their RX and TX pins. This made for a very easy hardware implementation, since we just have to use a mini ESP8266 board with its RX and TX connected to the Uno's TX and RX, plus VCC and GND, and all the rest of the wiring is already done. 

Next came the software. Because the project had 3 programmable devices that needed to work together, the programming quickly became way more complicated than I was expecting.

On the Raspberry Pi's end, our code was mostly an evolution of the Python programs we made during the lab periods. We re-used the historian page to see the messages in the ultrasonic sensor topic, and we improved on our manual publication page in order to publish movement messages from on-screen buttons. For the obstacle avoidance algorithm, we orignially wanted to use the rules json file for a clear namespace in which to create rules for the different possible actions in obstacle avoidance mode. However, as Hai and I deliberated about how the algorithm must work, we realized that the rules system was limiting, since only one action could be triggered per rule. We could have modified the python code that parsed the rules, or we could have made duplicate rules with the same conditions but a different action. In the end though, we decided to just abandon the rules system and hardcode the obstacle avoidance algorithm into the old IoT controller program. The algorithm consisted of a series of if statements in the on_message method of the IoT controller obect, which made decisions based on the latest distance measurement message received from the ESP, as well as previously recorded distance measurements. We realized that the code inside the on_message function could execute at any time, regardless of blocking delays in the rest of the program, so this function was quite useful for the Pi to react immediately to whatever the ESP publishes. The obstacle avoidance took some testing and troubleshooting to get working, since there were a lot of conditions that had to line up for each step in the algorithm to execute in a back-and-forth communication with the ESP. 
